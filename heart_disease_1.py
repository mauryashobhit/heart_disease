# -*- coding: utf-8 -*-
"""heart_disease_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14H5MmLf6RhOh_jyaY_j-V8HG3qaJky7q
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set(style="darkgrid")
import warnings
warnings.filterwarnings("ignore")

data=pd.read_csv("/content/drive/MyDrive/heart disease project/archive (2).zip (Unzipped Files)/heart.csv")

data.head()

data.shape

data.info()

data.describe()

data.isnull().sum()

pip install dataprep

from dataprep.eda import create_report
create_report(data)

x=data.drop(columns="target")
y=data.target

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)

from sklearn.feature_selection import mutual_info_classif
imp=mutual_info_classif(x,y)
feat_imp=pd.Series(imp,data.columns[0:len(data.columns)-1])
feat_imp.plot(kind="barh",color="teal")
plt.show()

from sklearn.ensemble import RandomForestClassifier
rf=RandomForestClassifier(n_estimators=100)
rf.fit(x,y)
importances=rf.feature_importances_
imp=pd.DataFrame({"features":pd.DataFrame(x).columns,"imp":importances})
imp.set_index("imp")
imp=imp.sort_values('imp')
imp.plot.bar(color="red")
imp

columns={"fbs","restecg","sex","slope","exang"}
data=data.drop(columns=columns,axis=1)

data

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)

from sklearn.metrics import confusion_matrix,accuracy_score

x_train.shape,y_train.shape,x_test.shape,y_test.shape

from sklearn.linear_model import LogisticRegression
clf=LogisticRegression()
clf.fit(x_train,y_train)
prd=clf.predict(x_test)
print(accuracy_score(prd,y_test))
confusion_matrix(prd,y_test)

from sklearn.ensemble import RandomForestClassifier
rlf=RandomForestClassifier()
rlf.fit(x_train,y_train)
rprd=rlf.predict(x_test)
print(accuracy_score(rprd,y_test))
confusion_matrix(rprd,y_test)

from sklearn.tree import DecisionTreeClassifier
dlf=DecisionTreeClassifier()
dlf.fit(x_train,y_train)
dprd=dlf.predict(x_test)
print(accuracy_score(dprd,y_test))
confusion_matrix(dprd,y_test)

from sklearn.model_selection import GridSearchCV
grid={"C":np.logspace(-3,3,7), "penalty":["l1","l2"]}# l1 lasso l2 ridge
logreg=LogisticRegression()
logreg_cv=GridSearchCV(logreg,grid,cv=10)
logreg_cv.fit(x_train,y_train)

print("tuned hpyerparameters :(best parameters) ",logreg_cv.best_params_)
print("accuracy :",logreg_cv.best_score_)

clf=LogisticRegression(C=1.0, class_weight=None, dual=False,
                                          fit_intercept=True,
                                          intercept_scaling=1, l1_ratio=None,
                                          max_iter=100, multi_class='auto',
                                          n_jobs=None, penalty='l2',
                                          random_state=None, solver='lbfgs',
                                          tol=0.0001, verbose=0,
                                          warm_start=False)

clf.fit(x_train,y_train)

l_pred=clf.predict(x_test)

print(accuracy_score(l_pred,y_test))
confusion_matrix(l_pred,y_test)

import pickle
filename = 'finalized_model_lg.sav'
pickle.dump(clf, open(filename, 'wb'))

loaded_model = pickle.load(open(filename, 'rb'))
result = loaded_model.score(x_test,y_test)
print(result)

